{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGUFSwNWoOt_"
   },
   "source": [
    "# NLP A3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FOviBnXoOuB"
   },
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbChzR24jv46"
   },
   "source": [
    "### Data Access and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vni5Ucako3QX"
   },
   "source": [
    "Google Colab Mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_IHQt5CE20U",
    "outputId": "677c9cb3-f24d-40ff-899c-2a86849a859d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from google.colab import drive  # importing drive module\\ndrive.mount('/content/drive') # mounts drive to my google drive\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from google.colab import drive  # importing drive module\n",
    "drive.mount('/content/drive') # mounts drive to my google drive\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHqrRYXIm6Qr",
    "outputId": "5371fb91-5eb0-4ba6-9174-2e74388f8613"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%cd /content/drive/MyDrive/Colab Notebooks/NLP_A3\\n# change directory to the folder I created for project to work out of...\\n# didn't realise this comment was causing bugs when on the line above for a while :)\\n!pwd  # print working directory to double check\\n!ls # seeing files within folder\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%cd /content/drive/MyDrive/Colab Notebooks/NLP_A3\n",
    "# change directory to the folder I created for project to work out of...\n",
    "# didn't realise this comment was causing bugs when on the line above for a while :)\n",
    "!pwd  # print working directory to double check\n",
    "!ls # seeing files within folder\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psqF82A0po7s"
   },
   "source": [
    "### Library Installion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrZbfzQJptGp"
   },
   "source": [
    "datasets: HF library for HF datasets\n",
    "\n",
    "evaluate: HF library for evaluating HF models\n",
    "\n",
    "transformers[sentenpiece]: HF transformers library with sentenpiece support (models that use sentenpiece) instead of wordpiece tokenization\n",
    "\n",
    "accelerate: HF enabled library to simplify training across models, and provide improved efficiency methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7xJOXWqoOuB",
    "outputId": "11e72b60-ce5c-4e4f-b0c0-30e35757e9a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"!pip install datasets evaluate 'transformers[sentencepiece]'\\n!pip install accelerate\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install datasets evaluate 'transformers[sentencepiece]'\n",
    "!pip install accelerate\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrLZvDqPfur9"
   },
   "source": [
    "# Loading Dataset - Master Coaching Hurstville"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WWyueQ5uGIT"
   },
   "source": [
    "Importing custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfkzcOz3Qlom",
    "outputId": "f3c3e860-6e99-4e58-96ab-6f834fa7cc1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length DF: 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "context",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answers",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f14f7ad4-a668-486c-a345-17c947bb8d40",
       "rows": [
        [
         "0",
         "0",
         "Subjects offered",
         "\"At our afterschool tuition center, we offer tutoring in English, Mathematics, Chemistry, Biology, and Physics to help students excel in their academic journey.\"",
         "What subjects do you offer tutoring in",
         "English, Mathematics, Chemistry, Biology, and Physics"
        ],
        [
         "1",
         "1",
         "Subjects offered",
         "\"Our dedicated teachers specialize in providing coaching for core subjects such as English, Maths, and Science. We aim to boost both knowledge and confidence.\"",
         "Which core subjects are available at your centre",
         "English, Maths, and Science"
        ],
        [
         "2",
         "2",
         "Subjects offered",
         "\"Students at our academy can enroll for support classes in English Literature, Advanced Mathematics, Chemistry, and Physics. We cater to both primary and secondary students.\"",
         "Which academic subjects do you provide support for",
         "English Literature, Advanced Mathematics, Chemistry, and Physics"
        ],
        [
         "3",
         "3",
         "Subjects offered",
         "\"Our afterschool programs include Mathematics tutoring, English writing workshops, and Science exam preparation. We focus on academic excellence and critical thinking.\"",
         "Which programs and subjcets are included in your tutoring",
         "Mathematics tutoring, English writing workshops, and Science exam preparation"
        ],
        [
         "4",
         "4",
         "Subjects offered",
         "\"We provide specialist tutoring services in Chemistry, Biology, Physics, English Language, and Mathematics. Personalized learning plans are designed for each student.\"",
         "What tutoring services do you offer in terms of subjects",
         "Chemistry, Biology, Physics, English Language, and Mathematics"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subjects offered</td>\n",
       "      <td>\"At our afterschool tuition center, we offer t...</td>\n",
       "      <td>What subjects do you offer tutoring in</td>\n",
       "      <td>English, Mathematics, Chemistry, Biology, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subjects offered</td>\n",
       "      <td>\"Our dedicated teachers specialize in providin...</td>\n",
       "      <td>Which core subjects are available at your centre</td>\n",
       "      <td>English, Maths, and Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subjects offered</td>\n",
       "      <td>\"Students at our academy can enroll for suppor...</td>\n",
       "      <td>Which academic subjects do you provide support...</td>\n",
       "      <td>English Literature, Advanced Mathematics, Chem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subjects offered</td>\n",
       "      <td>\"Our afterschool programs include Mathematics ...</td>\n",
       "      <td>Which programs and subjcets are included in yo...</td>\n",
       "      <td>Mathematics tutoring, English writing workshop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subjects offered</td>\n",
       "      <td>\"We provide specialist tutoring services in Ch...</td>\n",
       "      <td>What tutoring services do you offer in terms o...</td>\n",
       "      <td>Chemistry, Biology, Physics, English Language,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             title                                            context  \\\n",
       "0   0  Subjects offered  \"At our afterschool tuition center, we offer t...   \n",
       "1   1  Subjects offered  \"Our dedicated teachers specialize in providin...   \n",
       "2   2  Subjects offered  \"Students at our academy can enroll for suppor...   \n",
       "3   3  Subjects offered  \"Our afterschool programs include Mathematics ...   \n",
       "4   4  Subjects offered  \"We provide specialist tutoring services in Ch...   \n",
       "\n",
       "                                            question  \\\n",
       "0             What subjects do you offer tutoring in   \n",
       "1   Which core subjects are available at your centre   \n",
       "2  Which academic subjects do you provide support...   \n",
       "3  Which programs and subjcets are included in yo...   \n",
       "4  What tutoring services do you offer in terms o...   \n",
       "\n",
       "                                             answers  \n",
       "0  English, Mathematics, Chemistry, Biology, and ...  \n",
       "1                        English, Maths, and Science  \n",
       "2  English Literature, Advanced Mathematics, Chem...  \n",
       "3  Mathematics tutoring, English writing workshop...  \n",
       "4  Chemistry, Biology, Physics, English Language,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/ver2_1.csv') # converts CSV file into pandas dataframe to be used\n",
    "print(f\"Length DF: {len(df)}\")  # showing length to double check against ID to easily make sure I got all/bugs\n",
    "df.head(5)  # shows top 5 to quickly see data looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "w5LfCANp3orq",
    "outputId": "d4d54466-4edc-40ed-a9c2-9922f064c615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length DF: 49\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna() # drop NaN rows (indexes are pre-filled so there's a few)\n",
    "print(f\"Length DF: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZR2GWxMmA33"
   },
   "source": [
    "# Editing dataset to be format expected by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mxa4GfaRr_G",
    "outputId": "b8972d39-a310-48e6-c21d-1d0babc78bc6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\petea\\workspace\\github.com\\BL1TZau\\NLP-41043-A3\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 49\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'title': 'Subjects offered',\n",
       " 'context': '\"At our afterschool tuition center, we offer tutoring in English, Mathematics, Chemistry, Biology, and Physics to help students excel in their academic journey.\"',\n",
       " 'question': 'What subjects do you offer tutoring in',\n",
       " 'answers': {'answer_start': [57],\n",
       "  'text': ['English, Mathematics, Chemistry, Biology, and Physics']}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "my_data = []  # initialise empty list to build in\n",
    "\n",
    "for idx, row in df.iterrows():  # loop each item in the df (dataset)\n",
    "    context = row['context']  # assigning context\n",
    "    answer_text = row['answers']  # assigning answer\n",
    "\n",
    "    try:\n",
    "        answer_start = context.index(answer_text) # find character position of answer in context\n",
    "    except ValueError:  # generic error identification - shouldn't happen in mine with manual dataset\n",
    "        print(idx)\n",
    "        print(f\"❗ Warning: Could not find answer in context at row {idx}\")\n",
    "        continue  # Skip problematic row\n",
    "\n",
    "    sample = {                    # creating sample (data point) per row\n",
    "        \"id\": str(row['id']),\n",
    "        \"title\": row['title'],\n",
    "        \"context\": context,\n",
    "        \"question\": row['question'],\n",
    "        \"answers\": {\n",
    "            \"text\": [answer_text],\n",
    "            \"answer_start\": [answer_start]\n",
    "        }\n",
    "    }\n",
    "    my_data.append(sample)  # add sample to list\n",
    "\n",
    "dataset = Dataset.from_list(my_data)  # create hf dataset from list\n",
    "print(dataset)  # quickly check dataset characteristics\n",
    "dataset[0]  # Show first example to double check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p72U0t5MzAgn"
   },
   "source": [
    "### Creating train and test splits of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TwudRMFSSHU",
    "outputId": "d0e7999c-9e4d-43f5-894b-3b06b310962f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 39\n",
      "Validation samples: 10\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 39\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_list(my_data)  # create hf dataset\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)  # create 80 train 20 split on dataset\n",
    "\n",
    "MCH_train_dataset = dataset[\"train\"]  # create training dataset\n",
    "MCH_validation_dataset = dataset[\"test\"]  # create testing dataset\n",
    "\n",
    "# quick double check sizes of dataset\n",
    "print(f\"Training samples: {len(MCH_train_dataset)}\")\n",
    "print(f\"Validation samples: {len(MCH_validation_dataset)}\")\n",
    "print(dataset)  # quick check dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsvaOWJmzlsO"
   },
   "source": [
    "Quickly checking training samples to make sure it looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kk07B26dSo4T",
    "outputId": "bda94954-7686-401c-9822-2369a3fcb872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Example 0 ---\n",
      "ID:  18\n",
      "title:  class type\n",
      "Context:  Our entry into Year 7 English and Maths programs are designed to ensure a smooth and comfortable transition for the students. It is for the students who are finishing their Year 6 primary school and stepping into the Year 7 high school. Our Year 7 English Tutor and Year 7 Maths tutor, the major subjects which are usually of high concern for the students, conduct sessions for repeated revisions to master all the primary skills that are of high importance while stepping ahead in the high school. We introduce the Year 7 topics to the students slowly and steadily so that the students do not lag behind nor become shaky about it. As the students get used to the concepts and skills, the Year 7 English Tutor and Year 7 Maths tutor start nurturing and working on it further. Our tutors help the Year 6 students get accustomed to the techniques and methods used in the high school and help them learn to work on it\n",
      "Question:  Do you offer year 7 classes?\n",
      "Answer:  {'answer_start': [0], 'text': ['Our entry into Year 7 English and Maths programs are designed to ensure a smooth and comfortable transition for the students. It is for the students who are finishing their Year 6 primary school and stepping into the Year 7 high school. Our Year 7 English Tutor and Year 7 Maths tutor, the major subjects which are usually of high concern for the students, conduct sessions for repeated revisions to master all the primary skills that are of high importance while stepping ahead in the high school. ']}\n",
      "Answer Text:  ['Our entry into Year 7 English and Maths programs are designed to ensure a smooth and comfortable transition for the students. It is for the students who are finishing their Year 6 primary school and stepping into the Year 7 high school. Our Year 7 English Tutor and Year 7 Maths tutor, the major subjects which are usually of high concern for the students, conduct sessions for repeated revisions to master all the primary skills that are of high importance while stepping ahead in the high school. ']\n",
      "\n",
      "--- Training Example 1 ---\n",
      "ID:  38\n",
      "title:  class type\n",
      "Context:  There is a wide range of skills and knowledge covered in year 7-10 science. It is no wonder that many children find it challenging. Having a full comprehension of what is being taught in these junior years will ensure your child is ready to take on the challenges of the HSC. We offer science classes for all years 7-10.\n",
      "Question:  Do you teach Year 8 Science?\n",
      "Answer:  {'answer_start': [276], 'text': ['We offer science classes for all years 7-10.']}\n",
      "Answer Text:  ['We offer science classes for all years 7-10.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 2):\n",
    "  print(f\"--- Training Example {i} ---\")\n",
    "  print(\"ID: \", dataset[\"train\"][i][\"id\"])\n",
    "  print(\"title: \", dataset[\"train\"][i][\"title\"])\n",
    "  print(\"Context: \", dataset[\"train\"][i][\"context\"])\n",
    "  print(\"Question: \", dataset[\"train\"][i][\"question\"])\n",
    "  print(\"Answer: \", dataset[\"train\"][i][\"answers\"])  # answer_start field contains the starting character index of each answer in the context\n",
    "  print(\"Answer Text: \", dataset[\"train\"][i][\"answers\"]['text'])  # answer_start field contains the starting character index of each answer in the context)\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDylzM1K0McE"
   },
   "source": [
    "Double checking test set too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAS5S5JLUhFy",
    "outputId": "6060dffc-844e-4a0a-a39f-e5f798912555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Example 0 ---\n",
      "ID:  24\n",
      "title:  class type\n",
      "Context:  Master Coaching is offering an exclusive Holiday Enhancement Course – designed for students who wish to hone their knowledge, and stay ahead of their classmates. The course is open to students from year 2 to year 12. It is the best way to enjoy your holidays, make the most of the festivities, as well as, upgrade and strengthen your school’s assignments and syllabus. Master Coaching’s Holiday Enhancement Course includes English and Math tutoring, along with courses to help in OC preparation and basic curriculum. Achieving academic success is the number one priority for both parents and students. Getting ahead in class and acquiring the highest ranking, is what every student aims for. Having said this, you can accomplish such a goal, if you get trained and assisted by the best. We at Master Coaching understand the value of student goals and their aspirations – and strive to guide our pupils towards the road of academic success. Our Holiday Enhancement Course is developed around this student intent.\n",
      "Question:  Holiday sessions?\n",
      "Answer:  {'answer_start': [0], 'text': ['Master Coaching is offering an exclusive Holiday Enhancement Course – designed for students who wish to hone their knowledge, and stay ahead of their classmates. The course is open to students from year 2 to year 12. It is the best way to enjoy your holidays, make the most of the festivities, as well as, upgrade and strengthen your school’s assignments and syllabus. ']}\n",
      "Answer Text:  ['Master Coaching is offering an exclusive Holiday Enhancement Course – designed for students who wish to hone their knowledge, and stay ahead of their classmates. The course is open to students from year 2 to year 12. It is the best way to enjoy your holidays, make the most of the festivities, as well as, upgrade and strengthen your school’s assignments and syllabus. ']\n",
      "\n",
      "--- Test Example 1 ---\n",
      "ID:  33\n",
      "title:  class type\n",
      "Context:  At Master Coaching Hurstville, we believe Years 9-10 (Stage 5) are arguably even more important than Years 7-8, as they lead directly into the two senior years (Years 11-12). These years build on top of the foundations laid down in the junior years as well as prepare a student for the rigor and difficulty of the Higher School Certificate. We offer multiple different class sizes to fit your needs. The mathematical topic areas covered in the syllabus are nearly all identical to the junior years (with some notable exceptions, including trigonometry and financial mathematics) with the mere adjustment that they are explored in much more depth. This is why a solid grasp of these topics at a grass-roots level is of immense importance!\n",
      "Question:  Year 10 Math?\n",
      "Answer:  {'answer_start': [0], 'text': ['At Master Coaching Hurstville, we believe Years 9-10 (Stage 5) are arguably even more important than Years 7-8, as they lead directly into the two senior years (Years 11-12). These years build on top of the foundations laid down in the junior years as well as prepare a student for the rigor and difficulty of the Higher School Certificate. We offer multiple different class sizes to fit your needs.']}\n",
      "Answer Text:  ['At Master Coaching Hurstville, we believe Years 9-10 (Stage 5) are arguably even more important than Years 7-8, as they lead directly into the two senior years (Years 11-12). These years build on top of the foundations laid down in the junior years as well as prepare a student for the rigor and difficulty of the Higher School Certificate. We offer multiple different class sizes to fit your needs.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 2):\n",
    "  print(f\"--- Test Example {i} ---\")\n",
    "  print(\"ID: \", dataset[\"test\"][i][\"id\"])\n",
    "  print(\"title: \", dataset[\"test\"][i][\"title\"])\n",
    "  print(\"Context: \", dataset[\"test\"][i][\"context\"])\n",
    "  print(\"Question: \", dataset[\"test\"][i][\"question\"])\n",
    "  print(\"Answer: \", dataset[\"test\"][i][\"answers\"])  # answer_start field contains the starting character index of each answer in the context\n",
    "  print(\"Answer Text: \", dataset[\"test\"][i][\"answers\"]['text'])  # answer_start field contains the starting character index of each answer in the context)\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hjn2gluvQqTv"
   },
   "source": [
    "# Loading pre-trained model and AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2nnkRufoOuF",
    "outputId": "8fe7950a-9ced-4715-ce3e-84e2f61ba7e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "# AutoTokenizer: Loads correct tokenizer for any model checkpoint\n",
    "\"\"\" AutoModelForQuestionAnswering: Loads the model architecture designed to output answer spans from context. \"\"\"\n",
    "\n",
    "model_checkpoint = \"deepset/roberta-base-squad2\"  # model selection\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint) # loads tokenizer of specific model selected\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint) # loads QA model weights\n",
    "tokenizer.is_fast # checks if model supports HF accelerator: rust backend implementation to vastly increase efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiqxhnBi8sZb"
   },
   "source": [
    "Checking tokens visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWr7eL2woOuF",
    "outputId": "c9a768b4-4dc0-4e20-a77a-2aea5d95c61f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Question -- \n",
      "Do you offer year 7 classes?\n",
      "-- Context --\n",
      "Our entry into Year 7 English and Maths programs are designed to ensure a smooth and comfortable transition for the students. It is for the students who are finishing their Year 6 primary school and stepping into the Year 7 high school. Our Year 7 English Tutor and Year 7 Maths tutor, the major subjects which are usually of high concern for the students, conduct sessions for repeated revisions to master all the primary skills that are of high importance while stepping ahead in the high school. We introduce the Year 7 topics to the students slowly and steadily so that the students do not lag behind nor become shaky about it. As the students get used to the concepts and skills, the Year 7 English Tutor and Year 7 Maths tutor start nurturing and working on it further. Our tutors help the Year 6 students get accustomed to the techniques and methods used in the high school and help them learn to work on it\n",
      "\n",
      "-- Tokenized --\n",
      "{'input_ids': [0, 8275, 47, 904, 76, 262, 4050, 116, 2, 2, 2522, 3555, 88, 2041, 262, 2370, 8, 11945, 29, 1767, 32, 1887, 7, 1306, 10, 6921, 8, 3473, 3868, 13, 5, 521, 4, 85, 16, 13, 5, 521, 54, 32, 5614, 49, 2041, 231, 2270, 334, 8, 8296, 88, 5, 2041, 262, 239, 334, 4, 1541, 2041, 262, 2370, 25151, 368, 8, 2041, 262, 11945, 29, 38296, 6, 5, 538, 9352, 61, 32, 2333, 9, 239, 2212, 13, 5, 521, 6, 2883, 5453, 13, 6636, 24084, 7, 4710, 70, 5, 2270, 2417, 14, 32, 9, 239, 3585, 150, 8296, 789, 11, 5, 239, 334, 4, 166, 6581, 5, 2041, 262, 7614, 7, 5, 521, 5764, 8, 11844, 98, 14, 5, 521, 109, 45, 16396, 639, 3486, 555, 22032, 59, 24, 4, 287, 5, 521, 120, 341, 7, 5, 14198, 8, 2417, 6, 5, 2041, 262, 2370, 25151, 368, 8, 2041, 262, 11945, 29, 38296, 386, 30560, 8, 447, 15, 24, 617, 4, 1541, 15511, 994, 244, 5, 2041, 231, 521, 120, 21090, 7, 5, 7373, 8, 6448, 341, 11, 5, 239, 334, 8, 244, 106, 1532, 7, 173, 15, 24, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "-- Decoded --\n",
      "['<s>', 'Do', 'Ġyou', 'Ġoffer', 'Ġyear', 'Ġ7', 'Ġclasses', '?', '</s>', '</s>', 'Our', 'Ġentry', 'Ġinto', 'ĠYear', 'Ġ7', 'ĠEnglish', 'Ġand', 'ĠMath', 's', 'Ġprograms', 'Ġare', 'Ġdesigned', 'Ġto', 'Ġensure', 'Ġa', 'Ġsmooth', 'Ġand', 'Ġcomfortable', 'Ġtransition', 'Ġfor', 'Ġthe', 'Ġstudents', '.', 'ĠIt', 'Ġis', 'Ġfor', 'Ġthe', 'Ġstudents', 'Ġwho', 'Ġare', 'Ġfinishing', 'Ġtheir', 'ĠYear', 'Ġ6', 'Ġprimary', 'Ġschool', 'Ġand', 'Ġstepping', 'Ġinto', 'Ġthe', 'ĠYear', 'Ġ7', 'Ġhigh', 'Ġschool', '.', 'ĠOur', 'ĠYear', 'Ġ7', 'ĠEnglish', 'ĠTut', 'or', 'Ġand', 'ĠYear', 'Ġ7', 'ĠMath', 's', 'Ġtutor', ',', 'Ġthe', 'Ġmajor', 'Ġsubjects', 'Ġwhich', 'Ġare', 'Ġusually', 'Ġof', 'Ġhigh', 'Ġconcern', 'Ġfor', 'Ġthe', 'Ġstudents', ',', 'Ġconduct', 'Ġsessions', 'Ġfor', 'Ġrepeated', 'Ġrevisions', 'Ġto', 'Ġmaster', 'Ġall', 'Ġthe', 'Ġprimary', 'Ġskills', 'Ġthat', 'Ġare', 'Ġof', 'Ġhigh', 'Ġimportance', 'Ġwhile', 'Ġstepping', 'Ġahead', 'Ġin', 'Ġthe', 'Ġhigh', 'Ġschool', '.', 'ĠWe', 'Ġintroduce', 'Ġthe', 'ĠYear', 'Ġ7', 'Ġtopics', 'Ġto', 'Ġthe', 'Ġstudents', 'Ġslowly', 'Ġand', 'Ġsteadily', 'Ġso', 'Ġthat', 'Ġthe', 'Ġstudents', 'Ġdo', 'Ġnot', 'Ġlag', 'Ġbehind', 'Ġnor', 'Ġbecome', 'Ġshaky', 'Ġabout', 'Ġit', '.', 'ĠAs', 'Ġthe', 'Ġstudents', 'Ġget', 'Ġused', 'Ġto', 'Ġthe', 'Ġconcepts', 'Ġand', 'Ġskills', ',', 'Ġthe', 'ĠYear', 'Ġ7', 'ĠEnglish', 'ĠTut', 'or', 'Ġand', 'ĠYear', 'Ġ7', 'ĠMath', 's', 'Ġtutor', 'Ġstart', 'Ġnurturing', 'Ġand', 'Ġworking', 'Ġon', 'Ġit', 'Ġfurther', '.', 'ĠOur', 'Ġtut', 'ors', 'Ġhelp', 'Ġthe', 'ĠYear', 'Ġ6', 'Ġstudents', 'Ġget', 'Ġaccustomed', 'Ġto', 'Ġthe', 'Ġtechniques', 'Ġand', 'Ġmethods', 'Ġused', 'Ġin', 'Ġthe', 'Ġhigh', 'Ġschool', 'Ġand', 'Ġhelp', 'Ġthem', 'Ġlearn', 'Ġto', 'Ġwork', 'Ġon', 'Ġit', '</s>']\n"
     ]
    }
   ],
   "source": [
    "context = dataset[\"train\"][0][\"context\"]    # use first sample as example\n",
    "question = dataset[\"train\"][0][\"question\"]\n",
    "print(f\"-- Question -- \\n{question}\")\n",
    "print(f\"-- Context --\\n{context}\\n\")\n",
    "\n",
    "print(f\"-- Tokenized --\")\n",
    "tokens = tokenizer(question, context) # tokenize\n",
    "print(tokens) # print token ids\n",
    "print(f\"-- Decoded --\")\n",
    "print(tokenizer.convert_ids_to_tokens(tokens['input_ids'])) # print actual tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kTkwMip9Cez"
   },
   "source": [
    "# Sliding window tokenization for longer context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "L60hVhWBoOuF",
    "outputId": "c4361445-4b78-42b4-f458-7d1c9cde9202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 1, Len: 100\n",
      "<s>Do you offer year 7 classes?</s></s>Our entry into Year 7 English and Maths programs are designed to ensure a smooth and comfortable transition for the students. It is for the students who are finishing their Year 6 primary school and stepping into the Year 7 high school. Our Year 7 English Tutor and Year 7 Maths tutor, the major subjects which are usually of high concern for the students, conduct sessions for repeated revisions to master all the primary skills that are of high importance while stepping</s>\n",
      "Chunk: 2, Len: 100\n",
      "<s>Do you offer year 7 classes?</s></s> the Year 7 high school. Our Year 7 English Tutor and Year 7 Maths tutor, the major subjects which are usually of high concern for the students, conduct sessions for repeated revisions to master all the primary skills that are of high importance while stepping ahead in the high school. We introduce the Year 7 topics to the students slowly and steadily so that the students do not lag behind nor become shaky about it. As the students get used to the</s>\n",
      "Chunk: 3, Len: 100\n",
      "<s>Do you offer year 7 classes?</s></s> all the primary skills that are of high importance while stepping ahead in the high school. We introduce the Year 7 topics to the students slowly and steadily so that the students do not lag behind nor become shaky about it. As the students get used to the concepts and skills, the Year 7 English Tutor and Year 7 Maths tutor start nurturing and working on it further. Our tutors help the Year 6 students get accustomed to the techniques and methods</s>\n",
      "Chunk: 4, Len: 74\n",
      "<s>Do you offer year 7 classes?</s></s> shaky about it. As the students get used to the concepts and skills, the Year 7 English Tutor and Year 7 Maths tutor start nurturing and working on it further. Our tutors help the Year 6 students get accustomed to the techniques and methods used in the high school and help them learn to work on it</s>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer( # tokenizing\n",
    "    question, # getting question\n",
    "    context,  # getting answer\n",
    "    max_length=100, # set token maximum length\n",
    "    truncation=\"only_second\",   # keeping Q intact - truncate the second input(context) if question length > max_length\n",
    "    stride=50,  # allow model to see answers across splits - 50 tokens overlap between splits (are seen in both)\n",
    "    return_overflowing_tokens=True, # Required to make stride work --returns chunks of tokens. Otherwise returns one max_length token\n",
    ")\n",
    "z=0\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "    z+=1\n",
    "    print(f\"Chunk: {z}, Len: {len(ids)}\")\n",
    "    print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W29x-iqLQqTv"
   },
   "source": [
    "# Mapping tokens back to original character posiitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEr6N_11ALC6"
   },
   "source": [
    "Input mapping allows model to map token predictions back to character spans in the original sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOfbAmIEoOuF",
    "outputId": "8d1f326f-c8a4-44fb-81e7-b9c04099914a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])\n",
      "The 1 example gave 4 features (feature = each tokenized input, chunk) that will be fed to model\n",
      "Type of inputs[0]: <class 'tokenizers.Encoding'>\n",
      "Input mappings:  [(0, 0), (0, 2), (3, 6), (7, 12), (13, 17), (18, 19), (20, 27), (27, 28), (0, 0), (0, 0), (0, 3), (4, 9), (10, 14), (15, 19), (20, 21), (22, 29), (30, 33), (34, 38), (38, 39), (40, 48), (49, 52), (53, 61), (62, 64), (65, 71), (72, 73), (74, 80), (81, 84), (85, 96), (97, 107), (108, 111), (112, 115), (116, 124), (124, 125), (126, 128), (129, 131), (132, 135), (136, 139), (140, 148), (149, 152), (153, 156), (157, 166), (167, 172), (173, 177), (178, 179), (180, 187), (188, 194), (195, 198), (199, 207), (208, 212), (213, 216), (217, 221), (222, 223), (224, 228), (229, 235), (235, 236), (237, 240), (241, 245), (246, 247), (248, 255), (256, 259), (259, 261), (262, 265), (266, 270), (271, 272), (273, 277), (277, 278), (279, 284), (284, 285), (286, 289), (290, 295), (296, 304), (305, 310), (311, 314), (315, 322), (323, 325), (326, 330), (331, 338), (339, 342), (343, 346), (347, 355), (355, 356), (357, 364), (365, 373), (374, 377), (378, 386), (387, 396), (397, 399), (400, 406), (407, 410), (411, 414), (415, 422), (423, 429), (430, 434), (435, 438), (439, 441), (442, 446), (447, 457), (458, 463), (464, 472), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True, # makes each chunk of context own feature, lets us map feature to exact sample it originated from\n",
    "    return_offsets_mapping=True,    # returns tuple of (start_char, end_char) for each tuple, lets us trace tokens back to the original text\n",
    ")\n",
    "print(inputs.keys())\n",
    "print(f\"The 1 example gave {len(inputs['input_ids'])} features (feature = each tokenized input, chunk) that will be fed to model\")\n",
    "print(f\"Type of inputs[0]: {type(inputs[0])}\")\n",
    "print(\"Input mappings: \", inputs['offset_mapping'][0]) # Showing chars of first chunk - restarts at 9 because now context (truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoFa4OOmAnUF"
   },
   "source": [
    "Example showing how it points to each chunk to know where it came from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YY1VAhvoOuG",
    "outputId": "478b3fd6-b93f-440f-fd8b-16b782bf016b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4 examples gave 8 features (feature = chunk to be fed to model).\n",
      "Here is where each comes from: [0, 0, 0, 0, 1, 2, 2, 3].\n",
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    dataset[\"train\"][0:4][\"question\"],\n",
    "    dataset[\"train\"][0:4][\"context\"],\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "\n",
    "print(f\"The 4 examples gave {len(inputs['input_ids'])} features (feature = chunk to be fed to model).\")\n",
    "print(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")\n",
    "print(type(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxI3qE2eBjPM"
   },
   "source": [
    "# Aligning character answer spans with token positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qyNQRJMoOuG",
    "outputId": "7344173f-ace1-40f9-bc46-335e510b4cfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Example of i=0 --\n",
      "offset:[(0, 0), (0, 2), (3, 6), (7, 12), (13, 17), (18, 19), (20, 27), (27, 28), (0, 0), (0, 0), (0, 3), (4, 9), (10, 14), (15, 19), (20, 21), (22, 29), (30, 33), (34, 38), (38, 39), (40, 48), (49, 52), (53, 61), (62, 64), (65, 71), (72, 73), (74, 80), (81, 84), (85, 96), (97, 107), (108, 111), (112, 115), (116, 124), (124, 125), (126, 128), (129, 131), (132, 135), (136, 139), (140, 148), (149, 152), (153, 156), (157, 166), (167, 172), (173, 177), (178, 179), (180, 187), (188, 194), (195, 198), (199, 207), (208, 212), (213, 216), (217, 221), (222, 223), (224, 228), (229, 235), (235, 236), (237, 240), (241, 245), (246, 247), (248, 255), (256, 259), (259, 261), (262, 265), (266, 270), (271, 272), (273, 277), (277, 278), (279, 284), (284, 285), (286, 289), (290, 295), (296, 304), (305, 310), (311, 314), (315, 322), (323, 325), (326, 330), (331, 338), (339, 342), (343, 346), (347, 355), (355, 356), (357, 364), (365, 373), (374, 377), (378, 386), (387, 396), (397, 399), (400, 406), (407, 410), (411, 414), (415, 422), (423, 429), (430, 434), (435, 438), (439, 441), (442, 446), (447, 457), (458, 463), (464, 472), (0, 0)]\n",
      "\n",
      "-- Mapping feature to sample it came from --\n",
      "0\n",
      "\n",
      "-- Features and their Answers --\n",
      "Feature: 0, Answer: {'answer_start': [0], 'text': ['Our entry into Year 7 English and Maths programs are designed to ensure a smooth and comfortable transition for the students. It is for the students who are finishing their Year 6 primary school and stepping into the Year 7 high school. Our Year 7 English Tutor and Year 7 Maths tutor, the major subjects which are usually of high concern for the students, conduct sessions for repeated revisions to master all the primary skills that are of high importance while stepping ahead in the high school. ']}\n",
      "\n",
      "--Sequence ID of 0 chunk--\n",
      "[None, 0, 0, 0, 0, 0, 0, 0, None, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n",
      "\n",
      "-- Context start and end of i=0 --\n",
      "context_start: 10, context_end: 98\n",
      "\n",
      "-- idx of tokens within chunk -- \n",
      "start end top bottom. If 0 then answer not fully inside context\n",
      "[0, 0, 0, 0, 67, 9, 0, 12]\n",
      "[0, 0, 0, 0, 77, 38, 0, 20]\n"
     ]
    }
   ],
   "source": [
    "start_positions = []  # initalizing list for storing start\n",
    "end_positions = []  # initalizing list for storing end\n",
    "\n",
    "\"\"\" the added part if breaks \"\"\"\n",
    "answers = dataset[\"train\"][\"answers\"]\n",
    "\n",
    "# for chunkNumber, offset_mapping (char mapping of each word to original context)\n",
    "for i, offset in enumerate(inputs[\"offset_mapping\"]): # loop thru each chunks offstep mapping\n",
    "    if i == 0:\n",
    "        print(\"-- Example of i=0 --\")\n",
    "        print(f\"offset:{offset}\\n\") # showing offset\n",
    "\n",
    "    # Mapping feature to exact sample it came from\n",
    "    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]    # original dataset sample that chunk is\n",
    "\n",
    "    if i == 0: print(f\"-- Mapping feature to sample it came from --\\n{inputs['overflow_to_sample_mapping'][i]}\\n\")\n",
    "\n",
    "    answer = answers[sample_idx]  # assigns pecific answer for the current chunk (feature)\n",
    "    if i == 0: print(f\"-- Features and their Answers --\\nFeature: {sample_idx}, Answer: {answer}\\n\")\n",
    "\n",
    "    # get start_char and end_char\n",
    "    start_char = answer[\"answer_start\"][0]  # 0 bcos we set new answer each time\n",
    "    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "\n",
    "    # for each token in chunk, which part of input it came from? 0 = Q, 1 = Context, None = Special Token (SEP, CLS)\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "    if i == 0: print(f\"--Sequence ID of 0 chunk--\\n{sequence_ids}\\n\")\n",
    "\n",
    "    # Find start and end of context within chunk\n",
    "    idx = 0 # index\n",
    "    while sequence_ids[idx] != 1:   # increment while None (special token) or Question (0)\n",
    "        idx += 1\n",
    "    context_start = idx # becomes one, set start\n",
    "    while sequence_ids[idx] == 1: # hit context\n",
    "        idx += 1\n",
    "    context_end = idx - 1   # become None, set end to -1\n",
    "    if i == 0: print(f\"-- Context start and end of i=0 --\\ncontext_start: {context_start}, context_end: {context_end}\\n\")\n",
    "\n",
    "    # if the answer is not fully inside the context, label is (0, 0)\n",
    "    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "        start_positions.append(0)\n",
    "        end_positions.append(0)\n",
    "    else:\n",
    "        # otherwise it's the start and end token positions\n",
    "        idx = context_start # resetting idx (was context end from above)\n",
    "        # UNTIL idx (set as context_start) increments to ans start\n",
    "        while idx <= context_end and offset[idx][0] <= start_char:  # while index <= context_end and offset_mapping[index][startNo.] (here, 13) <= ans start\n",
    "            idx += 1\n",
    "        start_positions.append(idx - 1) # -1 bcos looping to past number\n",
    "\n",
    "        idx = context_end\n",
    "        # UNTIL idx (set as context_end) decrements to ans end\n",
    "        while idx >= context_start and offset[idx][1] >= end_char:  # while idx >= context_start and offset_mapping[index][endNo.] >= ans end\n",
    "            idx -= 1\n",
    "        end_positions.append(idx + 1)   # +1 bcos looping to before number\n",
    "\n",
    "print('-- idx of tokens within chunk -- \\nstart end top bottom. If 0 then answer not fully inside context')\n",
    "print(f\"{start_positions}\\n{end_positions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbJL7OzoOEZ3"
   },
   "source": [
    "# Preprocessing Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zaRr6j4ToOuG"
   },
   "outputs": [],
   "source": [
    "max_length = 384    # NEW -- max length of chunk\n",
    "stride = 128    # NEW -- stride (sliding window) size\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]   # NEW -- removes whitespaces (leading and trailing)\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True, # which feature came from which chunk\n",
    "        return_offsets_mapping=True,    # character spans\n",
    "        padding=\"max_length\",   # NEW -- pads to max_length with (0's or PAD token) if shorter, or truncates\n",
    "    )\n",
    "\n",
    "    # print(type(inputs)) # <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")   # character spans\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")   # which feature came from which chunk\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]  # feature it came from\n",
    "        answer = answers[sample_idx]    # ans\n",
    "        start_char = answer[\"answer_start\"][0]  # ans_start\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])   # ans_end\n",
    "        sequence_ids = inputs.sequence_ids(i)   # 0, 1, None of sequence (to find start of context)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:   # until seq id = 1\n",
    "            idx += 1\n",
    "        context_start = idx # set start\n",
    "        while sequence_ids[idx] == 1:   # while seq id == 1\n",
    "            idx += 1\n",
    "        context_end = idx - 1   # set end once no longer 1\n",
    "\n",
    "        # if the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            # UNTIL idx (set as context_start) increments to ans start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:  # while index <= context_end and offset_mapping[index][startNo.] (here, 13) <= ans start\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1) # -1 bcos looping to past number\n",
    "\n",
    "            idx = context_end\n",
    "            # UNTIL idx (set as context_end) decrements to ans end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:  # while idx >= context_start and offset_mapping[index][endNo.] >= ans end\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1) # +1 bcos looping to before number\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoDfon3TO_W1"
   },
   "source": [
    "# Preparing dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5xgMvVVoOuG",
    "outputId": "6aa557ae-dfe9-4cb0-eb04-507863005627"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 39/39 [00:00<00:00, 471.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39\n",
      "{'id': '18', 'title': 'class type', 'context': 'Our entry into Year 7 English and Maths programs are designed to ensure a smooth and comfortable transition for the students. It is for the students who are finishing their Year 6 primary school and stepping into the Year 7 high school. Our Year 7 English Tutor and Year 7 Maths tutor, the major subjects which are usually of high concern for the students, conduct sessions for repeated revisions to master all the primary skills that are of high importance while stepping ahead in the high school. We introduce the Year 7 topics to the students slowly and steadily so that the students do not lag behind nor become shaky about it. As the students get used to the concepts and skills, the Year 7 English Tutor and Year 7 Maths tutor start nurturing and working on it further. Our tutors help the Year 6 students get accustomed to the techniques and methods used in the high school and help them learn to work on it', 'question': 'Do you offer year 7 classes?', 'answers': {'answer_start': [0], 'text': ['Our entry into Year 7 English and Maths programs are designed to ensure a smooth and comfortable transition for the students. It is for the students who are finishing their Year 6 primary school and stepping into the Year 7 high school. Our Year 7 English Tutor and Year 7 Maths tutor, the major subjects which are usually of high concern for the students, conduct sessions for repeated revisions to master all the primary skills that are of high importance while stepping ahead in the high school. ']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"].map(  # applying fn over whole dataset to every sample (or batch of samples) in the dataset\n",
    "    preprocess_training_examples,   # Giving map fn - tokenizes, creates input_ids, attn_mask, token type ids, start and end positions\n",
    "    batched=True,   # Speed up - Pass a batch of examples to the function at once (as dictionaries of lists), instead of one-by-one\n",
    "    remove_columns=dataset[\"train\"].column_names,  # Removing no longer req original fields (id, question, context, answers)\n",
    ")\n",
    "print(len(dataset[\"train\"]), len(train_dataset))  # checking count counts of each\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm-dyScGQqTw"
   },
   "source": [
    "# Preprocessing Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nVKCDzl9oOuG"
   },
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    # examples is the dataset being fed in through map\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")   # which feature came from which chunk\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):   # for chunk in inputs\n",
    "        sample_idx = sample_map[i]  # sample index = correct feature where chunk came from (0... etc)\n",
    "        example_ids.append(examples[\"id\"][sample_idx])  # assigns sample_idx to actual hash of the id in dataset (56be4db0acb8001400a502ec... etc)\n",
    "        sequence_ids = inputs.sequence_ids(i)   # sequence_ids... 0, 1, None, i not sample_idx bcos sample can be from different chunk\n",
    "\n",
    "        # Removing question and special tokens from chunks (leaving just context)\n",
    "        offset = inputs[\"offset_mapping\"][i]    # list of tuples for chunk i, (start_char, end_char) - char span for token in original text\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "        # for each token in chunk, if seq_id = 1 (context) keep it, otherwise set to None (if 0 or None (Q, or Token))\n",
    "        # for index, actual in enumerate(offset)\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKdvpIHwoOuG",
    "outputId": "82e0aafd-ee26-4c65-89bf-50660007e2cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10/10 [00:00<00:00, 2189.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "{'id': '24', 'title': 'class type', 'context': 'Master Coaching is offering an exclusive Holiday Enhancement Course – designed for students who wish to hone their knowledge, and stay ahead of their classmates. The course is open to students from year 2 to year 12. It is the best way to enjoy your holidays, make the most of the festivities, as well as, upgrade and strengthen your school’s assignments and syllabus. Master Coaching’s Holiday Enhancement Course includes English and Math tutoring, along with courses to help in OC preparation and basic curriculum. Achieving academic success is the number one priority for both parents and students. Getting ahead in class and acquiring the highest ranking, is what every student aims for. Having said this, you can accomplish such a goal, if you get trained and assisted by the best. We at Master Coaching understand the value of student goals and their aspirations – and strive to guide our pupils towards the road of academic success. Our Holiday Enhancement Course is developed around this student intent.', 'question': 'Holiday sessions?', 'answers': {'answer_start': [0], 'text': ['Master Coaching is offering an exclusive Holiday Enhancement Course – designed for students who wish to hone their knowledge, and stay ahead of their classmates. The course is open to students from year 2 to year 12. It is the best way to enjoy your holidays, make the most of the festivities, as well as, upgrade and strengthen your school’s assignments and syllabus. ']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = dataset[\"test\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    ")\n",
    "print(len(dataset[\"test\"]), len(validation_dataset))\n",
    "print(dataset['test'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB5S5TR9QqTx"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTqVpsgvP9Wc",
    "outputId": "f99b0bde-28dd-470e-84cc-4c0f21b28d91"
   },
   "outputs": [],
   "source": [
    "import collections  # provides powerful container data types (defaultdict)\n",
    "# defaultdict: if you access a key that doesn’t exist yet, it will automatically create an empty list for you\n",
    "\n",
    "import evaluate # hf evaluate library to measure performance\n",
    "\n",
    "metric = evaluate.load(\"squad\") # used by original model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "528S1MT-QqT6"
   },
   "source": [
    "# Evaluation metrics fn - Turning logits from model output into answer spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lJDonNloOuH",
    "outputId": "33c2d23f-bb26-4a58-a9a8-65cc953fea5b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):  # takes model outputs (logits)\n",
    "    example_to_features = collections.defaultdict(list) # using defaultdict bcos if we access a key that doesn’t exist yet, it will automatically create an empty list\n",
    "\n",
    "    for idx, feature in enumerate(features):    # hash, chunk - which feature belongs to which context (sample)\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)  # '56be4db0acb8001400a502ec': [0], '56be4db0acb8001400a502ed': [1]\n",
    "\n",
    "    predicted_answers = []  # empty list\n",
    "    for example in examples:  # loop through original QA (not chunks) - want 1pred/Q (not per chunk)\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:   # FOR ALL CHUNKS OF QUESTION\n",
    "            start_logit = start_logits[feature_index] # get models answers\n",
    "            end_logit = end_logits[feature_index] # get models answers\n",
    "            offsets = features[feature_index][\"offset_mapping\"] # get offsets\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist() # sorting top 20 to be judged\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist() # sorting top 20\n",
    "\n",
    "            for start_index in start_indexes: # try all valid combos\n",
    "                for end_index in end_indexes:\n",
    "                    # skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "                    # VALID - puts answer and logit score into answers list\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)  # answer list to be judged\n",
    "\n",
    "        # select best answer\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples] # true label creation\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)  # F1 and exact match from HF lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYeGPTPRQqT6"
   },
   "source": [
    "# Fine-tuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1I_egIe3bxQ4"
   },
   "source": [
    "Redoing to have all in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "94bc6e3e3ca14a50aa7fe7d9708c3a01",
      "7ff8876fb39d4813851e9eaac631ea14",
      "351dc913381a431d947dce931f445a61",
      "bc583075317c4dedbe0bd03b9416130a",
      "44b77aa0c07d4a01b286ceaacec01c30",
      "b1fe4ff45a7c426786aa248ded8247ab",
      "0dcf05f832df4801a059792e073ce592",
      "2a530eae9aef440c9cbefd0eab5033aa",
      "4af5f3eab7f64e9295fbcfc3d3259e5d",
      "3deea57d2de24aed84f79bb23b2196de",
      "83c0bf0f109c434cbc4af2e250f58980",
      "cc80c4def4cc4cd787485537250f47f3",
      "a9fec220e3e349548ab8ef1270f9887b",
      "ea74d4281d73438d8d043a036c01fd64",
      "65dcd025492e45b1bae57ca9c5b19861",
      "4d6634c86b0c4848b51138b33491c2a6",
      "daf59db43c8a44c791936d58661d1a79",
      "cf7ef722890d4e98a99b3a4b0e7705cc",
      "bbbddffcb9ba4202907e1e172dcecc91",
      "73ae54b02eba4363b62ab3f550333a91",
      "d6d7619b26b445d2b452548d44f24c4d",
      "425701698cf84ec1b1208f2efa3a2b36",
      "d9498b54256a4ee297018ddab29c4ee9",
      "a59e3c2b2bf0453aa87dccba0c1f6ad0",
      "ed3a8d8ea84f4c74a720e2c304a1ccb5",
      "88ae91785bdf4b9db3c195f3929950c1",
      "d78afbc514c24f9996018577fbeb0732",
      "496885435e55495998fb80ce0ad8be82",
      "0d8f2f6d757242a6a24a4ef3722b9ab3",
      "c731863f06104b6196022eb857d8838e",
      "8dca35e4c08d446f899fc3b064216f62",
      "58b0b4afd69948189a3b32ae654d26d7",
      "1687338ae57441dbb5c4fc18929574ab",
      "e485ae3e38fb42cb84dc28ce7050f326",
      "7085a121cfa24836bb1a9414c4b54205",
      "e288b764a2c442f9b6ceca09546d56d9",
      "298ec50b88a94539b7960711cbc028ae",
      "284dd4cb94cb4a60aad028ac7a2045e1",
      "983d45963d314963bd672ac026f990f0",
      "b5814d7e2f1d44c0893b9ee57d9d03d3",
      "59710bf9665f46308d196951ae968ed3",
      "9091509ec8cf4aa5ae6d098ed17366e3",
      "a97760830c514b35b88b8d90ad8ee063",
      "9e4d138ca71c41a48c6529fe40a9d790",
      "7965594fb9e443ddbaf3d0fb8862e412",
      "1c908a5a493b4ab18443972baab5a1cd",
      "47c47d8d5979493fa2ee38950f6aed11",
      "6b2915003d0d4c179c02ced804351673",
      "5ecd7f62b8054090920909cdb335a414",
      "823dd902a7ed4f518b3a62d94e4e0ba3",
      "fcf84f63be134fefa6a601d02fe13fc8",
      "a7ef770c73054907bd16f785a0d80f29",
      "f949eab6a2eb4ea4a38c1fd914362332",
      "775c26b0830b455dbbf1523705e095e7",
      "8b6c313a5ae44302941f0a894ade44d5"
     ]
    },
    "id": "9JwKIlj2oOuS",
    "outputId": "f8f1c995-7168-4208-db34-fbc902296103"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "model_checkpoint_deepset = \"deepset/roberta-base-squad2\"\n",
    "tokenizer_deepset = AutoTokenizer.from_pretrained(model_checkpoint_deepset)\n",
    "model_deepset = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint_deepset)\n",
    "tokenizer_deepset.is_fast   # double checking model has fast tokenizer implemented\n",
    "\n",
    "model_checkpoint_bert = \"google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(model_checkpoint_bert)\n",
    "model_bert = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint_bert)\n",
    "tokenizer_bert.is_fast   # double checking model has fast tokenizer implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 5070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should be True\n",
    "print(torch.cuda.get_device_name(0))  # Should print your GPU name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Wj35pbApoOuS"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments  # holds all the training hyperparameters and behavior settings\n",
    "\n",
    "args = TrainingArguments(\n",
    "    eval_strategy=\"epoch\",   # eval per...\n",
    "    save_strategy=\"no\",  # do NOT save - was taking up too much google colab storage space\n",
    "    learning_rate=2e-5, # learning rate\n",
    "    num_train_epochs=3, # no. epoch. 3 seemed to generalise best after trying 1-15. Higher kept getting worse\n",
    "    weight_decay=0.01,  # regularisation: penalizes large weights, helps overfitting - standard small\n",
    "    fp16=True,  # mixed-precision training: HF optimisations to speed up training. Req. GPU\n",
    "    report_to='none', # cancel wand DB implementation, wasn't useful for this project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "21B8UnmLoOuS",
    "outputId": "b74e9d7f-61ca-413a-fd64-2720cfb53019"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\petea\\AppData\\Local\\Temp\\ipykernel_17516\\1545219770.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=2.662186686197917, metrics={'train_runtime': 1.2884, 'train_samples_per_second': 90.813, 'train_steps_per_second': 11.643, 'total_flos': 22928790403584.0, 'train_loss': 2.662186686197917, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEEPSET\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_deepset,    # model\n",
    "    args=args,  # args from above\n",
    "    train_dataset=train_dataset,    # trainin dataset\n",
    "    eval_dataset=validation_dataset,    # eval dataset\n",
    "    tokenizer=tokenizer_deepset,    # tokenizer\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "a32fe6c553ac4825b202c58df770980a",
      "3eb3b54fbc34440aa597db325fa78533",
      "af82f73950cf4e9f8d770c765a2cff84",
      "7ce818132acb418e9fb25d7de242b1e8",
      "0b9f98e8793c441499793daec2fccb70",
      "064506af1dd64e1a83a62191964316f8",
      "190340c751c04e8490cf6192061bb349",
      "7fd99c073f4348869f2aa5e385c5a772",
      "a3540c02c9ab4072bcb392f64847e996",
      "3548e47d6b3544cab25ba6d8237c3783",
      "84062d5983b44f6c86a3bed7c0c4c5cc"
     ]
    },
    "id": "E7213gq6oOuS",
    "outputId": "527671fb-8f69-4abe-a16d-3cccfea74076"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 60.0, 'f1': 75.26801142965427}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, _, _ = trainer.predict(validation_dataset)\n",
    "start_logits, end_logits = predictions\n",
    "compute_metrics(start_logits, end_logits, validation_dataset, dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "0nIx-Pl4aWlE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_contexts length: 25343, default_contexts length: 9716\n"
     ]
    }
   ],
   "source": [
    "all_contexts = dataset['train']['context'] + dataset['test']['context'] # combining all contexts from the training and test sets\n",
    "original_contexts = \" \".join(all_contexts)  # combining\n",
    "\n",
    "unique_contexts = list(set(all_contexts))   # removing duplicate contexts (do you vs teach vs offer creates a lot)\n",
    "unique_contexts.sort()  \n",
    "default_context = \" \".join(unique_contexts) # combining new set\n",
    "print(f\"all_contexts length: {len(original_contexts)}, default_contexts length: {len(default_context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "sJ9qIqf8MP1S"
   },
   "outputs": [],
   "source": [
    "possible_contexts = [\n",
    "    # 0 - OC Classes\n",
    "    \"At Master Coaching Hurstville, we offer extensive Opportunity Class (OC) preparation courses that build fundamental core skills needed in partaking in the exam. The OC exam is broken down into 3 parts; Thinking skills, mathematical reasoning and reading comprehension. In our OC preparation program, students will learn and develop a strong conceptual understanding of all key concepts in Maths, English and Thinking skills. Students will receive one on one support where our skilful tutor will cater to each students weakness and work along with them to perform their best. Each week we provide mock exams for students to practice the test under exam conditions and will then receive detailed feedback on where to improve. Tutors will also go through each question in a detailed manner and ensures to keep up with the student’s pace, ensuring they do not fall behind and motivate them to excel and build confidence.\",\n",
    "    # 1 - one on one tutoring\n",
    "    \"At master coaching hurstville, we offer One-to-One tutoring which allows us to customise the learning experience to each student’s unique needs, provide tailored support and boost confidence\",\n",
    "    # 2 - science + 7, 8, 9\n",
    "    \"There is a wide range of skills and knowledge covered in year 7-10 science. It is no wonder that many children find it challenging. Having a full comprehension of what is being taught in these junior years will ensure your child is ready to take on the challenges of the HSC. We offer science classes for all years 7-10.\",\n",
    "    # 3 - y10 sci\n",
    "    \"There is a wide range of skills and knowledge covered in year 7-10 science. It is no wonder that many children find it challenging. Having a full comprehension of what is being taught in these junior years will ensure your child is ready to take on the challenges of the HSC. We offer science classes for year 10, as well as HSC Subjects such as Chemistry, Biology and Physics.\",\n",
    "    # 4 - holiday\n",
    "    \"Master Coaching is offering an exclusive Holiday Enhancement Course – designed for students who wish to hone their knowledge, and stay ahead of their classmates. The course is open to students from year 2 to year 12. It is the best way to enjoy your holidays, make the most of the festivities, as well as, upgrade and strengthen your school’s assignments and syllabus. Master Coaching’s Holiday Enhancement Course includes English and Math tutoring, along with courses to help in OC preparation and basic curriculum. Achieving academic success is the number one priority for both parents and students. Getting ahead in class and acquiring the highest ranking, is what every student aims for. Having said this, you can accomplish such a goal, if you get trained and assisted by the best. We at Master Coaching understand the value of student goals and their aspirations – and strive to guide our pupils towards the road of academic success. Our Holiday Enhancement Course is developed around this student intent.\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zN9pn2nYZdyh",
    "outputId": "e5208a81-3c56-4f76-e076-e6a7c4ad45c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Question: Do you offer private tutoring?\n",
      "one or personal - possible_contexts[1]\n",
      "Context: At master coaching hurstville, we offer One-to-One tutoring which allows us to customise the learning experience to each student’s unique needs, provide tailored support and boost confidence\n",
      "{'score': 0.2856055796146393, 'start': 31, 'end': 59, 'answer': 'we offer One-to-One tutoring'}\n",
      "Chatbot Response: We offer one-to-one tutoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\petea\\workspace\\github.com\\BL1TZau\\NLP-41043-A3\\venv\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pipeline\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=model_deepset,\n",
    "    tokenizer=tokenizer_deepset,\n",
    ")\n",
    "\n",
    "print(\"---\")\n",
    "user_question = \"Do you offer private tutoring?\"\n",
    "\n",
    "print(f\"Question: {user_question}\")\n",
    "valid_question=1\n",
    "\n",
    "# oc\n",
    "if \"oc\" in user_question.lower():                       # oc\n",
    "  context = possible_contexts[0]\n",
    "  print(\"oc - possible_contexts[0]\")\n",
    "# one or personal\n",
    "elif \"one\" in user_question.lower() or \"personal\" in user_question.lower() or \"private\" in user_question.lower():                 # one or personal\n",
    "  context = possible_contexts[1]\n",
    "  print(\"one or personal - possible_contexts[1]\")\n",
    "# science\n",
    "elif \"science\" in user_question.lower():                                                                # science\n",
    "  if \"7\" in user_question.lower() or \"8\" in user_question.lower() or \"9\" in user_question.lower():          # 7, 8, 9\n",
    "    context = possible_contexts[2]\n",
    "    print(\"science + 7, 8, 9 - possible_contexts[2]\")\n",
    "  elif \"10\" in user_question.lower():                                                                       # 10\n",
    "    context = possible_contexts[3]\n",
    "    print(\"science + 10 - possible_contexts[3]\")\n",
    "  else:\n",
    "    context = default_context                                                                               # default\n",
    "    print(\"science else - default context\")\n",
    "# holiday\n",
    "elif \"holiday\" in user_question.lower():                                                                  # holiday\n",
    "  context = possible_contexts[4]\n",
    "  print(\"holiday - possible_contexts[4]\")\n",
    "# else\n",
    "else:\n",
    "  valid_question=0\n",
    "\n",
    "if valid_question==1:\n",
    "  # mock input\n",
    "  question = user_question\n",
    "  # ask\n",
    "  result = qa_pipeline({\n",
    "      \"context\": context,\n",
    "      \"question\": question\n",
    "  })\n",
    "else:\n",
    "  result = \"I'm here to help with Master Coaching Hurstville related questions only sorry! :(\"\n",
    "\n",
    "print(f\"Context: {context}\")\n",
    "print(result)\n",
    "print(f'Chatbot Response: {result['answer'][0].upper()+result['answer'][1:].lower()}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
